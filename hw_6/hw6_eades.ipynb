{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='text-align:center'>Homework 6</h1>\n",
    "<h2 style='text-align:center'>Caleb Eades</h2>\n",
    "<h2 style='text-align:center'>Due Date: April 2, 2018</h2>\n",
    "\n",
    "<h3>Notes:</h3>\n",
    "<p>\n",
    "<ul>\n",
    "<li>I use some globals in here to keep the name_map (mapping of category numbers to actual category names) and classifer (dictionary of the StandardScaler and RandomForestClassifier) objects readily available later.</li>\n",
    "<li>I didn't have time to run the training model using cross-validation so I have an accuracy of 100% on every category I tested which obviously means it doesn't mean much for future predictive power.</li>\n",
    "<li>Also, a big one, apparently my correlation features have 0 feature importance in the random forest, so either I implemented them wrong (which I don't think I did based on preliminary plots and tests on the images) or they are just extremely useless features (which I also kind of doubt). So there's probably a bug somewhere, but my forest still predicts the training data 100% (again a useless statistic other than to say that it works on the training set and isn't being completely guessing or anything). So given more time, I would probably seek out other features to replace these correlation ones or try to fix whatever weird bug is happening here.</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kceades/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:51: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from scipy.misc import imread\n",
    "\n",
    "def get_tail(string):\n",
    "    \"\"\"\n",
    "    Helper function for the get_subdirs function. It takes a directory\n",
    "    string and gives the name after the last backslash, thereby giving\n",
    "    the final subdirectory.\n",
    "    \n",
    "    :string: (str) string representing a specific directory\n",
    "    \n",
    "    :returns: (str) the name of the final subdirectory\n",
    "    \"\"\"\n",
    "    splits = string.split('/')\n",
    "    return splits[-1]\n",
    "\n",
    "def get_subdirs():\n",
    "    \"\"\"\n",
    "    Gets the subdirectories in the 50_categories folder where all the data\n",
    "    is stored.\n",
    "    \n",
    "    :returns: (list of str) the list of all the categories of images\n",
    "    \"\"\"\n",
    "    cwd = os.getcwd()\n",
    "    category_dir = cwd + '/50_categories'\n",
    "    # note the [1:] in the next line because for some reason os.walk gives\n",
    "    # the root directory as the first element, which we don't care about\n",
    "    subdirs = [get_tail(x[0]) for x in os.walk(category_dir)][1:]\n",
    "    return subdirs\n",
    "\n",
    "def get_image_paths(subdir_name):\n",
    "    \"\"\"\n",
    "    Gets all the images from the specified subdirectory of 50_categories.\n",
    "    \n",
    "    :subdir_name: (str) the name of the subdirectory (from get_subdirs)\n",
    "    \n",
    "    :returns: (list of str) list of all the direct image paths in the subfolder\n",
    "    \"\"\"\n",
    "    cwd = os.getcwd()\n",
    "    category_dir = cwd + '/50_categories'\n",
    "    # note the [1:] in the next line because for some reason os.walk gives\n",
    "    # the root directory as the first element, which we don't care about\n",
    "    return os.listdir(category_dir + '/' + subdir_name)\n",
    "\n",
    "def convert_images():\n",
    "    categories = get_subdirs()\n",
    "    category_map = {}\n",
    "    images = {}\n",
    "    for i,name in enumerate(categories):\n",
    "        category_map[i] = name\n",
    "        images[i] = [imread('./50_categories/{}/'.format(name) + image_name) for image_name in get_image_paths(name)]\n",
    "    return category_map,images\n",
    "\n",
    "name_map,images = convert_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.feature import structure_tensor,CENSURE\n",
    "\n",
    "def rgb_corr_features(image):\n",
    "    \"\"\"\n",
    "    Takes in an image (as a numpy array) and calculates correlations between\n",
    "    the rgb data and returns this as a tuple.\n",
    "    \n",
    "    :image: (numpy array, NxMx3) the input image\n",
    "    \n",
    "    :returns: (list of floats) correlation tuple (rg,rb,gb)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        r = image[:,:,0]\n",
    "        r = r.reshape(len(r)*len(r[0]))\n",
    "        g = image[:,:,1]\n",
    "        g = g.reshape(len(g)*len(g[0]))\n",
    "        b = image[:,:,2]\n",
    "        b = b.reshape(len(b)*len(b[0]))\n",
    "        adj_r = preprocessing.scale(r)\n",
    "        adj_g = preprocessing.scale(g)\n",
    "        adj_b = preprocessing.scale(b)\n",
    "        rg = np.corrcoef(adj_r,adj_g)[0][1]\n",
    "        rb = np.corrcoef(adj_r,adj_b)[0][1]\n",
    "        gb = np.corrcoef(adj_g,adj_b)[0][1]\n",
    "        return [rg,rb,gb]\n",
    "    except:\n",
    "        return [0,0,0] # default to no correlation\n",
    "    \n",
    "def aspect_ratio(image):\n",
    "    \"\"\"\n",
    "    Takes in an image (as a numpy array) and calculates the ratio of the\n",
    "    width to the height.\n",
    "    \n",
    "    :image: (numpy array, NxMx3) the input image\n",
    "    \n",
    "    :returns: (list of float) the ratio width/height\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return [len(image[0])/len(image)]\n",
    "    except:\n",
    "        return [1] # default to square image\n",
    "\n",
    "def mean_color_features(image):\n",
    "    \"\"\"\n",
    "    Takes in an image (as a numpy array) and calculates the mean of each\n",
    "    color in the image and returns this as a tuple.\n",
    "    \n",
    "    :image: (numpy array, NxMx3) the input image\n",
    "    \n",
    "    :returns: (list of floats) mean of the colors (r,g,b)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        r_mean = np.mean(image[:,:,0])\n",
    "        g_mean = np.mean(image[:,:,1])\n",
    "        b_mean = np.mean(image[:,:,2])\n",
    "        return [r_mean,g_mean,b_mean]\n",
    "    except:\n",
    "        return [122.5,122.5,122.5] # default to mean colors of half 255\n",
    "    \n",
    "def structure_tensor_features(image):\n",
    "    \"\"\"\n",
    "    Takes in an image (as a numpy array) and calculates the mean and std of each\n",
    "    Axx, Axy, and Ayy structure tensors and returns this as a tuple.\n",
    "    \n",
    "    :image: (numpy array, NxMx3) the input image\n",
    "    \n",
    "    :returns: (list of floats) mean and std of the structure tensors\n",
    "                with (Axx mean, Axx std, Axy mean, Axy std, Ayy mean, Ayy std)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        Axx,Axy,Ayy = structure_tensor(np.mean(image,axis=2))\n",
    "        return [np.mean(Axx),np.std(Axx)\\\n",
    "               ,np.mean(Axy),np.std(Axy)\\\n",
    "               ,np.mean(Ayy),np.std(Ayy)]\n",
    "    except:\n",
    "        return [0,0,0,0,0,0] # default to no structure and no variance\n",
    "    \n",
    "def censure_features(image):\n",
    "    \"\"\"\n",
    "    Takes in an image (as a numpy array) and calculates the mean and std\n",
    "    of the scales of the keypoints and returns this as a tuple.\n",
    "    \n",
    "    :image: (numpy array, NxMx3) the input image\n",
    "    \n",
    "    :returns: (list of floats) mean and std of the CENSURE scales\n",
    "    \"\"\"\n",
    "    try:\n",
    "        censure = CENSURE()\n",
    "        censure.detect(np.mean(image,axis=2))\n",
    "        scales = censure.scales\n",
    "        return [np.mean(scales),np.std(scales)]\n",
    "    except:\n",
    "        return [0,0] # default to no keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_map = {'censure':censure_features\\\n",
    "              ,'structure':structure_tensor_features\\\n",
    "              ,'mean_color':mean_color_features\\\n",
    "              ,'aspect':aspect_ratio\\\n",
    "              ,'color_corr':rgb_corr_features}\n",
    "\n",
    "def get_features(image):\n",
    "    \"\"\"\n",
    "    Gets all the features of the images and returns them in an array\n",
    "    together using the feature methods written above.\n",
    "    \n",
    "    :image: (numpy array, NxMx3) the input image\n",
    "    \n",
    "    :returns: (list of floats) the features\n",
    "    \"\"\"\n",
    "    final_features = []\n",
    "    for feature in feature_map:\n",
    "        final_features.extend(feature_map[feature](image))\n",
    "    return final_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def create_classifier():\n",
    "    \"\"\"\n",
    "    Creates the random forest classifier using the features written\n",
    "    above.\n",
    "    \n",
    "    :returns: (tuple) tuple of (StandardScaler,RandomForestClassifier) objects\n",
    "    \"\"\"\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    for key in name_map:\n",
    "        for image in images[key]:\n",
    "            X_train.append(get_features(image))\n",
    "            Y_train.append(key)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    forest = RandomForestClassifier(n_estimators=100)\n",
    "    forest.fit(X_train,Y_train)\n",
    "    return scaler,forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here in the line below that I created the classifier with a block of code such as:\n",
    "\n",
    "s,f = create_classifier()\n",
    "\n",
    "and then dumped a dictionary of {'scaler':s,'classifier':f} into a pickled file so I could load it up quickly later rather than regenerating every time I opened up the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "class_file = open('classifier.p','wb')\n",
    "s,f = create_classifier()\n",
    "pickle.dump({'scaler':s,'classifier':f},class_file)\n",
    "class_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_file = open('classifier.p','rb')\n",
    "classifier = pickle.load(class_file)\n",
    "class_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results below, the most important features are (in order):\n",
    "<ol>\n",
    "<li>Standard deviation of the Axy structure tensor feature.</li>\n",
    "<li>Standard deviation of the Axx structure tensor feature.</li>\n",
    "<li>The mean blue color of the image.</li>\n",
    "</ol>\n",
    "Note that I got this because I inputted features into the classifier in the order of:\n",
    "<ol>\n",
    "<li>Censure features (2 of them)</li>\n",
    "<li>Structure tensor features (6 of them)</li>\n",
    "<li>Mean color features (3 of them)</li>\n",
    "<li>Aspect feature (1 of them)</li>\n",
    "<li>Color correlation feature (3 of them)</li>\n",
    "</ol>\n",
    "The exact features are detailed above in the input cell that has all the feature calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.07325902  0.07002834  0.07813482  0.07871519  0.06936508  0.08177909\n",
      "  0.07728593  0.0732853   0.07578348  0.07621652  0.07867366  0.16747358\n",
      "  0.          0.          0.        ]\n",
      "censure\n",
      "structure\n",
      "mean_color\n",
      "aspect\n",
      "color_corr\n"
     ]
    }
   ],
   "source": [
    "classifier.keys()\n",
    "print(classifier['classifier'].feature_importances_)\n",
    "for feature in feature_map:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_on_training():\n",
    "    \"\"\"\n",
    "    Tests the classifier on the training sample to see\n",
    "    how much better it did than random guessing (I realize\n",
    "    this isn't cross validation but my classifier took\n",
    "    a long time to build and I didn't have time to wait\n",
    "    for each run in a full cross validation).\n",
    "    \"\"\"\n",
    "    successes = 0\n",
    "    failures = 0\n",
    "    for key in name_map:\n",
    "        for image in images[key]:\n",
    "            X_test = get_features(image)\n",
    "            scaled = classifier['scaler'].transform([X_test])\n",
    "            category = classifier['classifier'].predict(scaled)\n",
    "            if category[0]==key:\n",
    "                successes += 1\n",
    "            else:\n",
    "                failures += 1\n",
    "        break # only testing on the first category\n",
    "    print('Error rate of {:.2f} percent.'.format(failures*100/(successes+failures)))\n",
    "    print('Random guessing error rate: 98 percent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As detailed above in the docstring, the following line doesn't really mean much: it just says that the error rate is 0 (on only the first category) because I'm testing on the training sample that was used to generate the classifier. I didn't have enough time to do full k-fold cross validation based on the amount of time it was taking to get the features and build the classifier for each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate of 0.00 percent.\n",
      "Random guessing error rate: 98 percent\n"
     ]
    }
   ],
   "source": [
    "test_on_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_final_classifier(directory):\n",
    "    in_dir = os.listdir(directory)\n",
    "    files = [file for file in in_dir if os.path.isfile(os.path.join(directory,file))]\n",
    "    images = []\n",
    "    for file in files:\n",
    "        images.append((file,imread(os.path.join(directory,file))))\n",
    "    log_file = open('log_file.txt','w')\n",
    "    log_file.write('File Name \\t\\t\\t Classification \\n')\n",
    "    for image in images:\n",
    "        X = get_features(image[1])\n",
    "        scaled = classifier['scaler'].transform([X])\n",
    "        category = classifier['classifier'].predict(scaled)[0]\n",
    "        log_file.write(image[0] + ' \\t\\t\\t {} \\n'.format(name_map[category]))\n",
    "    log_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following line tests the log file creation using one of the given categories, which it does work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kceades/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "run_final_classifier('./50_categories/dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
